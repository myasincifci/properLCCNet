{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_tTeB3Rp2AU"
      },
      "source": [
        "# Test correlation module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nEELfIBKo-kO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from spatial_correlation_sampler import spatial_correlation_sample, SpatialCorrelationSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0rjtH6VfOt1P"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\"\n",
        "batch_size = 1\n",
        "channel = 3\n",
        "H = 10\n",
        "W = 10\n",
        "dtype = torch.float32\n",
        "\n",
        "input1 = torch.randint(1, 4, (batch_size, channel, H, W), dtype=dtype, device=device, requires_grad=True)\n",
        "input2 = torch.randint_like(input1, 1, 4).requires_grad_(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "poN8UiYKpBVl"
      },
      "outputs": [],
      "source": [
        "# out = spatial_correlation_sample(input1,\n",
        "#                                     input2,\n",
        "#                                     kernel_size=1,\n",
        "#                                     patch_size=5, #max displacement\n",
        "#                                     stride=1,\n",
        "#                                     padding=5,\n",
        "#                                     dilation_patch=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "stZUwWPOsHYP"
      },
      "outputs": [],
      "source": [
        "corr = SpatialCorrelationSampler(\n",
        "    kernel_size=1,\n",
        "    patch_size=5, # max displacement\n",
        "    stride=1,\n",
        "    padding=5,\n",
        "    dilation_patch=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7_t-cyt_sTBX"
      },
      "outputs": [],
      "source": [
        "out = corr(input1, input2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iwtuX0NpJnT",
        "outputId": "65894c09-0e62-45d3-c2e5-5c820700313a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 5, 20, 20])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rHFpIlz6pO7x"
      },
      "outputs": [],
      "source": [
        "b, ph, pw, h, w = out.size()\n",
        "out_corr = out.view(b, ph * pw, h, w)/input1.size(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_YQ6TRZpawa",
        "outputId": "fe1c3b98-c669-48f0-f029-28e7d749f842"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 25, 20, 20])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_corr.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIgeeSD-psWr"
      },
      "source": [
        "# Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "47uWE-NWqfFz"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TObmt3eTrEY5"
      },
      "outputs": [],
      "source": [
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uagJxB80qoWX"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "juRvuXqqpylh"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RHW01wd4q66g"
      },
      "outputs": [],
      "source": [
        "class SEBottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None, reduction=16):\n",
        "        super(SEBottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.leakyRELU = nn.LeakyReLU(0.1)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.leakyRELU(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.leakyRELU(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.attention(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.leakyRELU(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p8PkWrkarKQG"
      },
      "outputs": [],
      "source": [
        "class ResnetEncoder(nn.Module):\n",
        "    \"\"\"Pytorch module for a resnet encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, num_layers, pretrained, num_input_images=1):\n",
        "        super(ResnetEncoder, self).__init__()\n",
        "\n",
        "        self.num_ch_enc = np.array([64, 64, 128, 256, 512])\n",
        "\n",
        "        resnets = {18: models.resnet18,\n",
        "                   34: models.resnet34,\n",
        "                   50: models.resnet50,\n",
        "                   101: models.resnet101,\n",
        "                   152: models.resnet152}\n",
        "\n",
        "        if num_layers not in resnets:\n",
        "            raise ValueError(\"{} is not a valid number of resnet layers\".format(num_layers))\n",
        "\n",
        "        self.encoder = resnets[num_layers](pretrained)\n",
        "\n",
        "        if num_layers > 34:\n",
        "            self.num_ch_enc[1:] *= 4\n",
        "\n",
        "    def forward(self, input_image):\n",
        "        self.features = []\n",
        "        x = (input_image - 0.45) / 0.225\n",
        "        x = self.encoder.conv1(x)\n",
        "        x = self.encoder.bn1(x)\n",
        "        self.features.append(self.encoder.relu(x))\n",
        "        # self.features.append(self.encoder.layer1(self.encoder.maxpool(self.features[-1])))\n",
        "        self.features.append(self.encoder.maxpool(self.features[-1]))\n",
        "        self.features.append(self.encoder.layer1(self.features[-1]))\n",
        "        self.features.append(self.encoder.layer2(self.features[-1]))\n",
        "        self.features.append(self.encoder.layer3(self.features[-1]))\n",
        "        self.features.append(self.encoder.layer4(self.features[-1]))\n",
        "\n",
        "        return self.features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4WE8DDuSrlec"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = conv1x1(inplanes, planes)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.elu = nn.ELU()\n",
        "        self.leakyRELU = nn.LeakyReLU(0.1)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.leakyRELU(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.leakyRELU(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.leakyRELU(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ez8fMUmGtt7M"
      },
      "outputs": [],
      "source": [
        "def myconv(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation,\n",
        "                  groups=1, bias=True),\n",
        "        nn.LeakyReLU(0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z8ayWzcbtySr"
      },
      "outputs": [],
      "source": [
        "def predict_flow(in_planes):\n",
        "    return nn.Conv2d(in_planes, 2, kernel_size=3, stride=1, padding=1, bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AEJYy3pWt2Sk"
      },
      "outputs": [],
      "source": [
        "def deconv(in_planes, out_planes, kernel_size=4, stride=2, padding=1):\n",
        "    return nn.ConvTranspose2d(in_planes, out_planes, kernel_size, stride, padding, bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TM7W4VN-qp4C"
      },
      "outputs": [],
      "source": [
        "class LCCNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Based on the PWC-DC net. add resnet encoder, dilation convolution and densenet connections\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_size, use_feat_from=1, md=4, use_reflectance=False, dropout=0.0,\n",
        "                 Action_Func='leakyrelu', attention=False, res_num=18):\n",
        "        \"\"\"\n",
        "        input: md --- maximum displacement (for correlation. default: 4), after warpping\n",
        "        \"\"\"\n",
        "        super(LCCNet, self).__init__()\n",
        "        input_lidar = 1\n",
        "        self.res_num = res_num\n",
        "        self.use_feat_from = use_feat_from\n",
        "        if use_reflectance:\n",
        "            input_lidar = 2\n",
        "\n",
        "        # original resnet\n",
        "        self.pretrained_encoder = True\n",
        "        self.net_encoder = ResnetEncoder(num_layers=self.res_num, pretrained=True, num_input_images=1)\n",
        "\n",
        "        # resnet with leakyRELU\n",
        "        self.Action_Func = Action_Func\n",
        "        self.attention = attention\n",
        "        self.inplanes = 64\n",
        "        if self.res_num == 50:\n",
        "            layers = [3, 4, 6, 3]\n",
        "            add_list = [1024, 512, 256, 64]\n",
        "        elif self.res_num == 18:\n",
        "            layers = [2, 2, 2, 2]\n",
        "            add_list = [256, 128, 64, 64]\n",
        "\n",
        "        if self.attention:\n",
        "            block = SEBottleneck\n",
        "        else:\n",
        "            if self.res_num == 50:\n",
        "                block = Bottleneck\n",
        "            elif self.res_num == 18:\n",
        "                block = BasicBlock\n",
        "\n",
        "\n",
        "        # rgb_image\n",
        "        self.conv1_rgb = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.elu_rgb = nn.ELU()\n",
        "        self.leakyRELU_rgb = nn.LeakyReLU(0.1)\n",
        "        self.maxpool_rgb = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1_rgb = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2_rgb = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3_rgb = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4_rgb = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        # lidar_image\n",
        "        self.inplanes = 64\n",
        "        self.conv1_lidar = nn.Conv2d(input_lidar, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.elu_lidar = nn.ELU()\n",
        "        self.leakyRELU_lidar = nn.LeakyReLU(0.1)\n",
        "        self.maxpool_lidar = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1_lidar = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2_lidar = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3_lidar = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4_lidar = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        #self.corr = Correlation(pad_size=md, kernel_size=1, max_displacement=md, stride1=1, stride2=1, corr_multiply=1)\n",
        "        # self.corr = SpatialCorrelationSampler(\n",
        "        #     kernel_size=1,\n",
        "        #     patch_size=(2 * md + 1), # max displacement\n",
        "        #     stride=1,\n",
        "        #     padding=0,#md,\n",
        "        #     dilation_patch=1\n",
        "        # )\n",
        "\n",
        "        self.corr = SpatialCorrelationSampler(\n",
        "            kernel_size=1,\n",
        "            patch_size=(2 * md + 1), # max displacement\n",
        "            stride=1,\n",
        "            padding=0,#md,\n",
        "            dilation=1,\n",
        "            dilation_patch=2\n",
        "        )\n",
        "\n",
        "        self.leakyRELU = nn.LeakyReLU(0.1)\n",
        "\n",
        "        nd = (2 * md + 1) ** 2\n",
        "        dd = np.cumsum([128, 128, 96, 64, 32])\n",
        "\n",
        "        od = nd\n",
        "        self.conv6_0 = myconv(od, 128, kernel_size=3, stride=1)\n",
        "        self.conv6_1 = myconv(od + dd[0], 128, kernel_size=3, stride=1)\n",
        "        self.conv6_2 = myconv(od + dd[1], 96, kernel_size=3, stride=1)\n",
        "        self.conv6_3 = myconv(od + dd[2], 64, kernel_size=3, stride=1)\n",
        "        self.conv6_4 = myconv(od + dd[3], 32, kernel_size=3, stride=1)\n",
        "\n",
        "        if use_feat_from > 1:\n",
        "            self.predict_flow6 = predict_flow(od + dd[4])\n",
        "            self.deconv6 = deconv(2, 2, kernel_size=4, stride=2, padding=1)\n",
        "            self.upfeat6 = deconv(od + dd[4], 2, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "            od = nd + add_list[0] + 4\n",
        "            self.conv5_0 = myconv(od, 128, kernel_size=3, stride=1)\n",
        "            self.conv5_1 = myconv(od + dd[0], 128, kernel_size=3, stride=1)\n",
        "            self.conv5_2 = myconv(od + dd[1], 96, kernel_size=3, stride=1)\n",
        "            self.conv5_3 = myconv(od + dd[2], 64, kernel_size=3, stride=1)\n",
        "            self.conv5_4 = myconv(od + dd[3], 32, kernel_size=3, stride=1)\n",
        "\n",
        "        if use_feat_from > 2:\n",
        "            self.predict_flow5 = predict_flow(od + dd[4])\n",
        "            self.deconv5 = deconv(2, 2, kernel_size=4, stride=2, padding=1)\n",
        "            self.upfeat5 = deconv(od + dd[4], 2, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "            od = nd + add_list[1] + 4\n",
        "            self.conv4_0 = myconv(od, 128, kernel_size=3, stride=1)\n",
        "            self.conv4_1 = myconv(od + dd[0], 128, kernel_size=3, stride=1)\n",
        "            self.conv4_2 = myconv(od + dd[1], 96, kernel_size=3, stride=1)\n",
        "            self.conv4_3 = myconv(od + dd[2], 64, kernel_size=3, stride=1)\n",
        "            self.conv4_4 = myconv(od + dd[3], 32, kernel_size=3, stride=1)\n",
        "\n",
        "        if use_feat_from > 3:\n",
        "            self.predict_flow4 = predict_flow(od + dd[4])\n",
        "            self.deconv4 = deconv(2, 2, kernel_size=4, stride=2, padding=1)\n",
        "            self.upfeat4 = deconv(od + dd[4], 2, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "            od = nd + add_list[2] + 4\n",
        "            self.conv3_0 = myconv(od, 128, kernel_size=3, stride=1)\n",
        "            self.conv3_1 = myconv(od + dd[0], 128, kernel_size=3, stride=1)\n",
        "            self.conv3_2 = myconv(od + dd[1], 96, kernel_size=3, stride=1)\n",
        "            self.conv3_3 = myconv(od + dd[2], 64, kernel_size=3, stride=1)\n",
        "            self.conv3_4 = myconv(od + dd[3], 32, kernel_size=3, stride=1)\n",
        "\n",
        "        if use_feat_from > 4:\n",
        "            self.predict_flow3 = predict_flow(od + dd[4])\n",
        "            self.deconv3 = deconv(2, 2, kernel_size=4, stride=2, padding=1)\n",
        "            self.upfeat3 = deconv(od + dd[4], 2, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "            od = nd + add_list[3] + 4\n",
        "            self.conv2_0 = myconv(od, 128, kernel_size=3, stride=1)\n",
        "            self.conv2_1 = myconv(od + dd[0], 128, kernel_size=3, stride=1)\n",
        "            self.conv2_2 = myconv(od + dd[1], 96, kernel_size=3, stride=1)\n",
        "            self.conv2_3 = myconv(od + dd[2], 64, kernel_size=3, stride=1)\n",
        "            self.conv2_4 = myconv(od + dd[3], 32, kernel_size=3, stride=1)\n",
        "\n",
        "        if use_feat_from > 5:\n",
        "            self.predict_flow2 = predict_flow(od + dd[4])\n",
        "            self.deconv2 = deconv(2, 2, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "            self.dc_conv1 = myconv(od + dd[4], 128, kernel_size=3, stride=1, padding=1, dilation=1)\n",
        "            self.dc_conv2 = myconv(128, 128, kernel_size=3, stride=1, padding=2, dilation=2)\n",
        "            self.dc_conv3 = myconv(128, 128, kernel_size=3, stride=1, padding=4, dilation=4)\n",
        "            self.dc_conv4 = myconv(128, 96, kernel_size=3, stride=1, padding=8, dilation=8)\n",
        "            self.dc_conv5 = myconv(96, 64, kernel_size=3, stride=1, padding=16, dilation=16)\n",
        "            self.dc_conv6 = myconv(64, 32, kernel_size=3, stride=1, padding=1, dilation=1)\n",
        "            self.dc_conv7 = predict_flow(32)\n",
        "\n",
        "        fc_size = od + dd[4]\n",
        "        downsample = 128 // (2**use_feat_from)\n",
        "        if image_size[0] % downsample == 0:\n",
        "            fc_size *= image_size[0] // downsample\n",
        "        else:\n",
        "            fc_size *= (image_size[0] // downsample)+1\n",
        "        if image_size[1] % downsample == 0:\n",
        "            fc_size *= image_size[1] // downsample\n",
        "        else:\n",
        "            fc_size *= (image_size[1] // downsample)+1\n",
        "        self.fc1 = nn.Linear(fc_size * 4, 512)\n",
        "\n",
        "        self.fc1_trasl = nn.Linear(512, 256)\n",
        "        self.fc1_rot = nn.Linear(512, 256)\n",
        "\n",
        "        self.fc2_trasl = nn.Linear(256, 3)\n",
        "        self.fc2_rot = nn.Linear(256, 4)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                nn.init.kaiming_normal_(m.weight.data, mode='fan_in')\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    # def _make_layer(self, block, planes, blocks, stride=1):\n",
        "    #     layers = []\n",
        "    #     layers.append(block(self.inplanes, planes, 1))\n",
        "    #     self.inplanes = planes * block.expansion\n",
        "    #     for i in range(1, blocks - 1):\n",
        "    #         layers.append(block(self.inplanes, planes, 1))\n",
        "    #     layers.append(block(self.inplanes, planes, 2))\n",
        "    #\n",
        "    #     return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def warp(self, x, flo):\n",
        "        \"\"\"\n",
        "        warp an image/tensor (im2) back to im1, according to the optical flow\n",
        "        x: [B, C, H, W] (im2)\n",
        "        flo: [B, 2, H, W] flow\n",
        "        \"\"\"\n",
        "        B, C, H, W = x.size()\n",
        "        # mesh grid\n",
        "        xx = torch.arange(0, W).view(1, -1).repeat(H, 1)\n",
        "        yy = torch.arange(0, H).view(-1, 1).repeat(1, W)\n",
        "        xx = xx.view(1, 1, H, W).repeat(B, 1, 1, 1)\n",
        "        yy = yy.view(1, 1, H, W).repeat(B, 1, 1, 1)\n",
        "        grid = torch.cat((xx, yy), 1).float()\n",
        "\n",
        "        if x.is_cuda:\n",
        "            grid = grid.cuda()\n",
        "        vgrid = Variable(grid) + flo\n",
        "\n",
        "        # scale grid to [-1,1]\n",
        "        vgrid[:, 0, :, :] = 2.0 * vgrid[:, 0, :, :].clone() / max(W - 1, 1) - 1.0\n",
        "        vgrid[:, 1, :, :] = 2.0 * vgrid[:, 1, :, :].clone() / max(H - 1, 1) - 1.0\n",
        "\n",
        "        vgrid = vgrid.permute(0, 2, 3, 1)\n",
        "        output = nn.functional.grid_sample(x, vgrid)\n",
        "        mask = torch.autograd.Variable(torch.ones(x.size())).cuda()\n",
        "        mask = nn.functional.grid_sample(mask, vgrid)\n",
        "\n",
        "        # if W==128:\n",
        "        # np.save('mask.npy', mask.cpu().data.numpy())\n",
        "        # np.save('warp.npy', output.cpu().data.numpy())\n",
        "\n",
        "        # mask[mask<0.9999] = 0.0\n",
        "        # mask[mask>0] = 1.0\n",
        "        mask = torch.floor(torch.clamp(mask, 0, 1))\n",
        "\n",
        "        return output * mask\n",
        "\n",
        "    def forward(self, rgb, lidar):\n",
        "        H, W = rgb.shape[2:4]\n",
        "\n",
        "        #encoder\n",
        "        if self.pretrained_encoder:\n",
        "            # rgb_image\n",
        "            features1 = self.net_encoder(rgb)\n",
        "            c12 = features1[0]  # 2\n",
        "            c13 = features1[2]  # 4\n",
        "            c14 = features1[3]  # 8\n",
        "            c15 = features1[4]  # 16\n",
        "            c16 = features1[5]  # 32\n",
        "            # lidar_image\n",
        "            x2 = self.conv1_lidar(lidar)\n",
        "            if self.Action_Func == 'leakyrelu':\n",
        "                c22 = self.leakyRELU_lidar(x2)  # 2\n",
        "            elif self.Action_Func == 'elu':\n",
        "                c22 = self.elu_lidar(x2)  # 2\n",
        "            c23 = self.layer1_lidar(self.maxpool_lidar(c22))  # 4\n",
        "            c24 = self.layer2_lidar(c23)  # 8\n",
        "            c25 = self.layer3_lidar(c24)  # 16\n",
        "            c26 = self.layer4_lidar(c25)  # 32\n",
        "\n",
        "        else:\n",
        "            x1 = self.conv1_rgb(rgb)\n",
        "            x2 = self.conv1_lidar(lidar)\n",
        "            if self.Action_Func == 'leakyrelu':\n",
        "                c12 = self.leakyRELU_rgb(x1)  # 2\n",
        "                c22 = self.leakyRELU_lidar(x2)  # 2\n",
        "            elif self.Action_Func == 'elu':\n",
        "                c12 = self.elu_rgb(x1)  # 2\n",
        "                c22 = self.elu_lidar(x2)  # 2\n",
        "            c13 = self.layer1_rgb(self.maxpool_rgb(c12))  # 4\n",
        "            c23 = self.layer1_lidar(self.maxpool_lidar(c22))  # 4\n",
        "            c14 = self.layer2_rgb(c13)  # 8\n",
        "            c24 = self.layer2_lidar(c23)  # 8\n",
        "            c15 = self.layer3_rgb(c14)  # 16\n",
        "            c25 = self.layer3_lidar(c24)  # 16\n",
        "            c16 = self.layer4_rgb(c15)  # 32\n",
        "            c26 = self.layer4_lidar(c25)  # 32\n",
        "\n",
        "        print(c16.shape, c26.shape)\n",
        "\n",
        "        corr6 = self.corr(c16, c26)\n",
        "\n",
        "        print(corr6.shape)\n",
        "\n",
        "        b, ph, pw, h, w = corr6.size()\n",
        "        corr6 = corr6.view(b, ph * pw, h, w)/rgb.size(1)\n",
        "\n",
        "        corr6 = self.leakyRELU(corr6)\n",
        "\n",
        "        print(corr6.shape)\n",
        "\n",
        "        x = torch.cat((self.conv6_0(corr6), corr6), 1)\n",
        "        x = torch.cat((self.conv6_1(x), x), 1)\n",
        "        x = torch.cat((self.conv6_2(x), x), 1)\n",
        "        x = torch.cat((self.conv6_3(x), x), 1)\n",
        "        x = torch.cat((self.conv6_4(x), x), 1)\n",
        "\n",
        "        print(x.shape)\n",
        "\n",
        "        if self.use_feat_from > 1:\n",
        "            flow6 = self.predict_flow6(x)\n",
        "            up_flow6 = self.deconv6(flow6)\n",
        "            up_feat6 = self.upfeat6(x)\n",
        "\n",
        "            warp5 = self.warp(c25, up_flow6*0.625)\n",
        "            corr5 = self.corr(c15, warp5)\n",
        "            corr5 = self.leakyRELU(corr5)\n",
        "            x = torch.cat((corr5, c15, up_flow6, up_feat6), 1)\n",
        "            x = torch.cat((self.conv5_0(x), x), 1)\n",
        "            x = torch.cat((self.conv5_1(x), x), 1)\n",
        "            x = torch.cat((self.conv5_2(x), x), 1)\n",
        "            x = torch.cat((self.conv5_3(x), x), 1)\n",
        "            x = torch.cat((self.conv5_4(x), x), 1)\n",
        "\n",
        "        if self.use_feat_from > 2:\n",
        "            flow5 = self.predict_flow5(x)\n",
        "            up_flow5 = self.deconv5(flow5)\n",
        "            up_feat5 = self.upfeat5(x)\n",
        "\n",
        "            warp4 = self.warp(c24, up_flow5*1.25)\n",
        "            corr4 = self.corr(c14, warp4)\n",
        "            corr4 = self.leakyRELU(corr4)\n",
        "            x = torch.cat((corr4, c14, up_flow5, up_feat5), 1)\n",
        "            x = torch.cat((self.conv4_0(x), x), 1)\n",
        "            x = torch.cat((self.conv4_1(x), x), 1)\n",
        "            x = torch.cat((self.conv4_2(x), x), 1)\n",
        "            x = torch.cat((self.conv4_3(x), x), 1)\n",
        "            x = torch.cat((self.conv4_4(x), x), 1)\n",
        "\n",
        "        if self.use_feat_from > 3:\n",
        "            flow4 = self.predict_flow4(x)\n",
        "            up_flow4 = self.deconv4(flow4)\n",
        "            up_feat4 = self.upfeat4(x)\n",
        "\n",
        "            warp3 = self.warp(c23, up_flow4*2.5)\n",
        "            corr3 = self.corr(c13, warp3)\n",
        "            corr3 = self.leakyRELU(corr3)\n",
        "            x = torch.cat((corr3, c13, up_flow4, up_feat4), 1)\n",
        "            x = torch.cat((self.conv3_0(x), x),1)\n",
        "            x = torch.cat((self.conv3_1(x), x),1)\n",
        "            x = torch.cat((self.conv3_2(x), x),1)\n",
        "            x = torch.cat((self.conv3_3(x), x),1)\n",
        "            x = torch.cat((self.conv3_4(x), x),1)\n",
        "\n",
        "        if self.use_feat_from > 4:\n",
        "            flow3 = self.predict_flow3(x)\n",
        "            up_flow3 = self.deconv3(flow3)\n",
        "            up_feat3 = self.upfeat3(x)\n",
        "\n",
        "\n",
        "            warp2 = self.warp(c22, up_flow3*5.0)\n",
        "            corr2 = self.corr(c12, warp2)\n",
        "            corr2 = self.leakyRELU(corr2)\n",
        "            x = torch.cat((corr2, c12, up_flow3, up_feat3), 1)\n",
        "            x = torch.cat((self.conv2_0(x), x), 1)\n",
        "            x = torch.cat((self.conv2_1(x), x), 1)\n",
        "            x = torch.cat((self.conv2_2(x), x), 1)\n",
        "            x = torch.cat((self.conv2_3(x), x), 1)\n",
        "            x = torch.cat((self.conv2_4(x), x), 1)\n",
        "\n",
        "        if self.use_feat_from > 5:\n",
        "            flow2 = self.predict_flow2(x)\n",
        "\n",
        "            x = self.dc_conv4(self.dc_conv3(self.dc_conv2(self.dc_conv1(x))))\n",
        "            #flow2 = flow2 + self.dc_conv7(self.dc_conv6(self.dc_conv5(x)))\n",
        "\n",
        "        print(x.shape)\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.leakyRELU(self.fc1(x))\n",
        "\n",
        "        transl = self.leakyRELU(self.fc1_trasl(x))\n",
        "        rot = self.leakyRELU(self.fc1_rot(x))\n",
        "        transl = self.fc2_trasl(transl)\n",
        "        rot = self.fc2_rot(rot)\n",
        "        rot = F.normalize(rot, dim=1)\n",
        "\n",
        "        return transl, rot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QNyCS-afur97"
      },
      "outputs": [],
      "source": [
        "input_size = (256, 512)\n",
        "feat = 1\n",
        "md = 4\n",
        "use_reflectance = False\n",
        "dropout = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BywinV9tuNam",
        "outputId": "96f5b8f5-a722-415f-e2f2-0ffb7b3b69db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yasin/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/home/yasin/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = LCCNet(\n",
        "    input_size,\n",
        "    use_feat_from=feat,\n",
        "    md=md,\n",
        "    use_reflectance=use_reflectance,\n",
        "    dropout=dropout,\n",
        "    Action_Func='leakyrelu',\n",
        "    attention=False,\n",
        "    res_num=18\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GLZg_501vJkb"
      },
      "outputs": [],
      "source": [
        "rgb, lidar = torch.rand((8,3,*input_size)).to(device), torch.rand((8,1,*input_size)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyOv9QRm1cJM",
        "outputId": "4f8d1e7b-ef0e-47d2-b3da-45ab72837e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 512, 8, 16]) torch.Size([8, 512, 8, 16])\n",
            "torch.Size([8, 9, 9, 8, 16])\n",
            "torch.Size([8, 81, 8, 16])\n",
            "torch.Size([8, 529, 8, 16])\n",
            "torch.Size([8, 529, 8, 16])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[ 4.1685,  6.2173, -1.4598],\n",
              "         [ 4.8241,  5.0353, -3.8274],\n",
              "         [ 4.2863,  3.5221, -3.2677],\n",
              "         [ 5.1956,  6.3060, -1.6871],\n",
              "         [ 6.8432,  9.8142, -3.5995],\n",
              "         [ 4.2927,  7.7079, -1.8159],\n",
              "         [ 5.7529,  6.4430, -1.9099],\n",
              "         [ 3.8203,  6.7586, -2.8324]], device='cuda:0',\n",
              "        grad_fn=<AddmmBackward0>),\n",
              " tensor([[-0.2769,  0.3151, -0.8530, -0.3105],\n",
              "         [-0.1011, -0.0141, -0.9597, -0.2620],\n",
              "         [-0.3277,  0.0605, -0.8445, -0.4192],\n",
              "         [-0.3437,  0.2631, -0.8786, -0.2016],\n",
              "         [-0.4491,  0.2247, -0.8261, -0.2555],\n",
              "         [-0.4976,  0.2176, -0.8091, -0.2247],\n",
              "         [-0.3631,  0.1891, -0.8708, -0.2722],\n",
              "         [-0.3694,  0.1850, -0.8711, -0.2656]], device='cuda:0',\n",
              "        grad_fn=<DivBackward0>))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(rgb, lidar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO71q1Gj2gWv",
        "outputId": "6c7da8cb-5d7f-4745-84b8-f9f02ea245ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "203136"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "529*16*24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaZyWgmA3Ex-",
        "outputId": "b71ff598-4251-4f7c-ed58-e2dff0455571"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "67712"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "529*8*16"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
